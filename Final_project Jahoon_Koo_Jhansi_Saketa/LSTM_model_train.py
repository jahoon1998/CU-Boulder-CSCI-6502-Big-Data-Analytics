# -*- coding: utf-8 -*-
"""Stock Price prediction w twitter sentiment analysis_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xP-rNqCyer1q60EkgBClIdyodtPwRV82
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing the Libraries
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib. pyplot as plt
import matplotlib
from sklearn.preprocessing import MinMaxScaler
from keras.layers import LSTM, Dense, Dropout
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib. dates as mandates
from sklearn.preprocessing import MinMaxScaler
from sklearn import linear_model
from keras.models import Sequential
from keras.layers import Dense
import keras.backend as K
from keras.callbacks import EarlyStopping
import pickle 
from tensorflow.keras.optimizers import Adam
from keras.models import load_model
from keras.layers import LSTM
from keras.utils.vis_utils import plot_model

!sklearn --version

# from google.colab import drive
# drive.mount('/content/drive')

stock_prices_data = pd.read_csv("/content/stock_prices.csv", index_col= 0, parse_dates= True)

stock_prices_data.shape

stock_prices_data.head()

stock_prices_data.tail()

twitter_sentiment_analysis_data = pd.read_csv("/content/twitter_sentiment.csv", index_col= 0, parse_dates= True)

twitter_sentiment_analysis_data.shape

twitter_sentiment_analysis_data.head()

twitter_sentiment_analysis_data.tail()

data = stock_prices_data.merge(twitter_sentiment_analysis_data, on = "Date")

data.shape

data.head()

data.tail()

data["Adj Close"][0]

#Set Target Variable
output_var = pd.DataFrame(data["Adj Close"]).iloc[2: , :]
#Selecting the Features
features = ["Open", "High",	"Low",	"Adj Close", "Close",	"ts_polarity"]

# adj close value the day after
output_var["Adj Close"]

#Scaling
scaler = MinMaxScaler()
feature_transform = scaler.fit_transform(data[features])
feature_transform= pd.DataFrame(columns=features, data=feature_transform, index=data.index)
feature_transform = feature_transform.iloc[1:-1 , :]

feature_transform.head()

feature_transform.tail()

#Splitting to Training set and Test set
timesplit= TimeSeriesSplit(n_splits=10)
for train_index, test_index in timesplit.split(feature_transform):
        X_train, X_test = feature_transform[:len(train_index)], feature_transform[len(train_index): (len(train_index)+len(test_index))]
        y_train, y_test = output_var[:len(train_index)].values.ravel(), output_var[len(train_index): (len(train_index)+len(test_index))].values.ravel()

X_train.head()

y_train[:5]

#Process the data for LSTM
trainX =np.array(X_train)
testX =np.array(X_test)
X_train = trainX.reshape(X_train.shape[0], 1, X_train.shape[1])
X_test = testX.reshape(X_test.shape[0], 1, X_test.shape[1])

#Building the LSTM Model
lstm = Sequential()
lstm.add(LSTM(32, input_shape=(1, trainX.shape[1]), activation='relu', return_sequences=False))
lstm.add(Dense(1))
lstm.compile(loss='mean_squared_error', optimizer='adam')
plot_model(lstm, show_shapes=True, show_layer_names=True)
#Train the model
history=lstm.fit(X_train, y_train, epochs=150, batch_size=8, verbose=1, shuffle=False)

y_pred= lstm.predict(X_test)

#Predicted vs True Adj Close Value â€“ LSTM
plt.plot(y_test, label='True Value')
plt.plot(y_pred, label='LSTM Value')
plt.title("Prediction by LSTM")
plt.xlabel("Time Scale")
plt.ylabel("Scaled USD")
plt.legend()
plt.show()

def training_loss_graph(history):
    plt.plot(history.history['loss'], label = 'Training  Loss')
    plt.legend()
    plt.xlabel("Epochs")
    plt.ylabel('Loss')
    plt.show()
training_loss_graph(history)

from sklearn.metrics import mean_squared_error
from numpy import sqrt
rmse = sqrt(mean_squared_error(y_test, y_pred))

print("Root Mean Squared Error: {}".format(rmse))
